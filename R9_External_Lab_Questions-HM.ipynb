{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R9_External_Lab_Questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WPJHV_CIn6Bg"
      },
      "source": [
        "# U - Net\n",
        "## Problem: \n",
        "\n",
        "Seismic data is collected using reflection seismology, or seismic reflection. The method requires a controlled seismic source of energy, such as compressed air or a seismic vibrator, and sensors record the reflection from rock interfaces within the subsurface. The recorded data is then processed to create a 3D view of earth’s interior. Reflection seismology is similar to X-ray, sonar and echolocation.\n",
        "\n",
        "A seismic image is produced from imaging the reflection coming from rock boundaries. The seismic image shows the boundaries between different rock types. In theory, the strength of reflection is directly proportional to the difference in the physical properties on either sides of the interface. While seismic images show rock boundaries, they don't say much about the rock themselves; some rocks are easy to identify while some are difficult.\n",
        "\n",
        "There are several areas of the world where there are vast quantities of salt in the subsurface. One of the challenges of seismic imaging is to identify the part of subsurface which is salt. Salt has characteristics that makes it both simple and hard to identify. Salt density is usually 2.14 g/cc which is lower than most surrounding rocks. The seismic velocity of salt is 4.5 km/sec, which is usually faster than its surrounding rocks. This difference creates a sharp reflection at the salt-sediment interface. Usually salt is an amorphous rock without much internal structure. This means that there is typically not much reflectivity inside the salt, unless there are sediments trapped inside it. The unusually high seismic velocity of salt can create problems with seismic imaging.\n",
        "\n",
        "### Data\n",
        "The data is a set of images chosen at various locations chosen at random in the subsurface. The images are 101 x 101 pixels and each pixel is classified as either salt or sediment. In addition to the seismic images, the depth of the imaged location is provided for each image. The goal of the competition is to segment regions that contain salt.\n",
        "\n",
        "#### Source: \n",
        "https://www.kaggle.com/c/tgs-salt-identification-challenge\n",
        "\n",
        "\n",
        "### Note: \n",
        "Accept the terms and download data from the above link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3OKrTNUtn-od"
      },
      "source": [
        "### Aim: \n",
        "\n",
        "Implement U-Net neural model architecture in keras to solve this problem.\n",
        "\n",
        "\n",
        "In this, you are asked to segment salt deposits beneath the Earth’s surface. Given a set of seismic images that are 101 x 101 pixels each and each pixel we need to classify as either salt or sediment. Our goal is to segment regions that contain salt. A seismic image is produced from imaging the reflection coming from rock boundaries. The seismic image shows the boundaries between different rock types. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZUOAF8WWoA1x"
      },
      "source": [
        "### Broad Steps:\n",
        "\n",
        "1. Download the dataset\n",
        "2. Upload to Drive\n",
        "3. Import from drive to colab\n",
        "4. Load the images and create training data.\n",
        "5. Build U-net Model\n",
        "6. Train your model.\n",
        "7. Check the validation accuracy and plot sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b7TLNzB6oDep",
        "colab": {}
      },
      "source": [
        "#Importing necessary libraries\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6qiCvW9coD_E",
        "outputId": "996efadf-a08a-45b8-d0c9-4d840d8a442e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B4IaUgploION"
      },
      "source": [
        "### 1.Set your project path where you have your data and related files for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tPkbXWyoK-z",
        "colab": {}
      },
      "source": [
        "project_path = '../content/gdrive/My Drive/Colab Notebooks/NLP/'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kxy5LexhoLMT",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g15qSXZSoSuL"
      },
      "source": [
        "### 2. Set the necessary parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dzrz2Or_HdxR"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3IEaEnuzoW2a",
        "colab": {}
      },
      "source": [
        "im_width = 128      #width of your train image\n",
        "im_height = 128     #hight of your train image\n",
        "#border =        \n",
        "path_train = project_path + 'train/'   #Path for your train data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1gzQNwtWGnz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a440669c-1702-494d-c5d7-0801fc9c9e59"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZQyyn55oKW-",
        "outputId": "323a4462-d97b-49fb-b033-92719216db52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "os.chdir(project_path)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-bbb54c1e00d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../content/gdrive/My Drive/Colab Notebooks/NLP/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2uvocpoSSrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "670d05ec-2a08-4cda-f57d-d0b9e14e2f49"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q3IoS6RCoZPh"
      },
      "source": [
        "# 3. Make directory for train data at in your project/lab folder.\n",
        "\n",
        "Hint - use !mkdir function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MRPpQ2QrocBQ",
        "colab": {}
      },
      "source": [
        "#Directory Already Present"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RWATodbkocN9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "1599a8e7-c74b-454d-e735-f328eaab3f42"
      },
      "source": [
        "os.chdir('.\\train')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-9b6a008e984a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.\\train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dikin2Xsoof",
        "colab_type": "code",
        "outputId": "a8a958fa-ddc7-46cc-c17a-e9cd6bf63bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/train'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fRbC22DGoeb7"
      },
      "source": [
        "# 4. Extract your train images to the train directory you have just created above. \n",
        "train.zip and test.zip files available at your google drive/local system.\n",
        "\n",
        "As a good practice - Upload or copy the data at your project path folder.\n",
        "\n",
        "Make sure you are providing the right project_path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5BtPznFbogjG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "66cf321a-4d43-4cf5-8efa-40d59699dc7c"
      },
      "source": [
        "#For simplicity we have added the required code here.\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(project_path + 'train.zip', 'r') as zf:\n",
        "    zf.extractall('train/')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-40aaa3619c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzipfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mzf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../content/gdrive/My Drive/Colab Notebooks/NLP/train.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7YZ2prb9oiX4",
        "colab": {}
      },
      "source": [
        "#The train file have both images and masks with the same names_ids."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zxQ1u8Bvoj1M",
        "colab": {}
      },
      "source": [
        "#Above Done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iwCH81ZWomLA"
      },
      "source": [
        "### 5. Get the list of names of images and masks and name the list imagelist and masklist.\n",
        "\n",
        "Hint - Use os.listdir() funtions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Clt5ya_JoplC",
        "outputId": "a37a7c10-04f6-4ef8-92fd-fcbb751422e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "os.chdir('images')\n",
        "os.getcwd()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-8d21eff72670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux7Z_kkVsoop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagelist = os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNWrgZkIsooq",
        "colab_type": "code",
        "outputId": "ade09688-a2f7-4f72-8e71-4f8cb71b1356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "os.chdir('../masks/')\n",
        "os.getcwd()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-d2edc311952b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../masks/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../masks/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk0B8M6vsoos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "masklist = os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-vHPQoHVoppK",
        "outputId": "949cd6c5-48b6-484d-c460-4f11c3188465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Test your list names by printing some of the names as given below.\n",
        "print(imagelist[-1])\n",
        "print(masklist[-1])\n",
        "print(imagelist[10])\n",
        "print(masklist[10])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Black-grass\n",
            "Black-grass\n",
            "Charlock\n",
            "Charlock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQJURJMCunZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('../')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz9BgEh5utol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeEa-JslyBVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "masklist = masklist[:4000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyFPTwB1yJAr",
        "colab_type": "code",
        "outputId": "27cd8cf2-964e-436c-d2e6-d8d865ac7f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(masklist)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1t8raFq5ous8"
      },
      "source": [
        "# 6. Read and test your images and respective masks.\n",
        "\n",
        "Hint -\n",
        "\n",
        "import  matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "\n",
        "plt.imshow(cv2.imread('path of image'))\n",
        "\n",
        "plt.imshow(cv2.imread('path of mask'))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1gGpCSPpovvH",
        "outputId": "dd84189b-1abd-4462-bac4-08e120d03315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "plt.imshow(cv2.imread('images/' + imagelist[-1]), cmap=plt.cm.Greys)\n",
        "plt.show()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-f4b421b5b270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimagelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGreys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    632\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    633\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqbAYJBX/D6fDIo1bJ4F7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9E-McW2toyaR",
        "outputId": "82cbe8bc-cae2-4ec9-c8e7-9537ca3f7fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "plt.imshow(cv2.imread('masks/' + masklist[-1]), cmap=plt.cm.Greys)\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-6c2992694431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'masks/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmasklist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGreys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    632\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    633\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqbAYJBX/D6fDIo1bJ4F7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_qFeroMNoylc"
      },
      "source": [
        "# 7. Create your training data.\n",
        "\n",
        "Hints - \n",
        "\n",
        "image_path = os.path.join(project_path +'path of your image directory' +n )\n",
        "\n",
        "mask_path = os.path.join(project_path +'path of your mask directory'+n )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJbRVbL4o1qT",
        "outputId": "fe3c6748-e55e-43c0-8efb-0ce098a115d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        }
      },
      "source": [
        "# Get and resize train images and masks\n",
        "def get_data():\n",
        "    X = np.zeros(((1000, im_height, im_width, 1)), dtype=np.float32) # Create an array for image\n",
        "    y = np.zeros(((1000, im_height, im_width, 1)), dtype=np.float32) #Create an array for mask\n",
        "    \n",
        "    for index, n in enumerate(imagelist): \n",
        "        k = imagelist.index(n)\n",
        "        ##Add image_path\n",
        "        image_path = os.path.join('images/' + n)\n",
        "        ##Add mask_path\n",
        "        mask_path = os.path.join('masks/' + n)                                                       \n",
        "        \n",
        "        # Load images and resize to (128,128,1)\n",
        "        im = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        resized_img = cv2.resize(im, (128, 128), cv2.INTER_LINEAR)\n",
        "\n",
        "        # Load masks and resize to (128,128,1)\n",
        "        ma = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        resized_mask = cv2.resize(ma, (128, 128), cv2.INTER_LINEAR)\n",
        "        \n",
        "        # Save images\n",
        "        X[k, ..., 0] = resized_img.squeeze() / 255\n",
        "        y[k, ..., 0] = resized_mask.squeeze() / 255\n",
        "        \n",
        "        if(index%50 == 0):\n",
        "          print(index)\n",
        "        if(index == 999):\n",
        "          break\n",
        "    print('Done!')\n",
        "    return X, y\n",
        "    \n",
        "X, y = get_data()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-b2d61633029a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-104-b2d61633029a>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Load images and resize to (128,128,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresized_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Load masks and resize to (128,128,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /io/opencv/modules/imgproc/src/resize.cpp:4044: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kt6zXJPHo35y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "36307751-4fd5-4164-c64a-d9930c2c8ecb"
      },
      "source": [
        "# Split train and valid\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=2019)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-c36a0b33fdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mh_SRFGro6wr",
        "outputId": "2577ae0d-9998-4dfd-e8fa-72361ebd1560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "## Test your data whether it looks fine - Random check\n",
        "import random \n",
        "# Check if training data looks all right\n",
        "ix = random.randint(0, len(X_train))\n",
        "has_mask = y_train[ix].max() > 0\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "\n",
        "ax[0].imshow(X_train[ix, ..., 0], cmap='seismic', interpolation='bilinear')\n",
        "if has_mask:\n",
        "    ax[0].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\n",
        "ax[0].set_title('Seismic')\n",
        "\n",
        "ax[1].imshow(y_train[ix].squeeze(), interpolation='bilinear', cmap='gray')\n",
        "ax[1].set_title('Salt');"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-92f398c7e829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Check if training data looks all right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhas_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "em5jGV93o8qR"
      },
      "source": [
        "### 8. Define loss and dice_coeff function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uyxf8uhQpA78",
        "colab": {}
      },
      "source": [
        "def loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) - tf.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EmCjyEUUpA_V",
        "colab": {}
      },
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
        "    denominator = tf.reduce_sum(y_true + y_pred)\n",
        "\n",
        "    return numerator / (denominator + tf.keras.backend.epsilon())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ofKZA-9pDVJ"
      },
      "source": [
        "### 9. Build and compile UNet Model for your data.\n",
        "\n",
        "Hint - \n",
        "You can install and use segmentation models from this github repository.\n",
        "\n",
        "#Install segmentation models\n",
        "\n",
        "!pip install git+https://github.com/qubvel/segmentation_models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85BPObnWsoo8",
        "colab_type": "code",
        "outputId": "3e828e86-f9f2-4718-8daa-54506f34c6d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "#Install segmentation models\n",
        "!pip install git+https://github.com/qubvel/segmentation_models"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/qubvel/segmentation_models\n",
            "  Cloning https://github.com/qubvel/segmentation_models to /tmp/pip-req-build-qyscpqz1\n",
            "  Running command git clone -q https://github.com/qubvel/segmentation_models /tmp/pip-req-build-qyscpqz1\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from segmentation-models==0.2.1) (2.2.4)\n",
            "Collecting keras_applications==1.0.7 (from segmentation-models==0.2.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from segmentation-models==0.2.1) (0.15.0)\n",
            "Collecting image-classifiers==0.2.0 (from segmentation-models==0.2.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/32/a1e74e03f74506d1e4b46bb2732ca5a7b18ac52a36b5e3547e63537ce74c/image_classifiers-0.2.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.2MB/s \n",
            "\u001b[?25hCollecting efficientnet>=0.0.3 (from segmentation-models==0.2.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/66/9c/8bee2927037da1a56e899eb62140fba2862a0d4faeeacbdbe7a1f27bd528/efficientnet-0.0.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->segmentation-models==0.2.1) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->segmentation-models==0.2.1) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->segmentation-models==0.2.1) (1.16.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->segmentation-models==0.2.1) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->segmentation-models==0.2.1) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.2.0->segmentation-models==0.2.1) (1.1.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.2.1) (3.0.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.2.1) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.2.1) (2.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.2.1) (4.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.2.1) (1.0.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.1) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.1) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.1) (2.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->segmentation-models==0.2.1) (4.4.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->segmentation-models==0.2.1) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->segmentation-models==0.2.1) (41.0.1)\n",
            "Building wheels for collected packages: segmentation-models\n",
            "  Building wheel for segmentation-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-riuanjd7/wheels/49/cf/46/cbb4bb64518c402aea99df9d466f1081450597e653256bbcf4\n",
            "Successfully built segmentation-models\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "  Found existing installation: Keras-Applications 1.0.8\n",
            "    Uninstalling Keras-Applications-1.0.8:\n",
            "      Successfully uninstalled Keras-Applications-1.0.8\n",
            "Successfully installed efficientnet-0.0.3 image-classifiers-0.2.0 keras-applications-1.0.7 segmentation-models-0.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras_applications"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "456utznCpGco",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "ee66e979-b11f-4a1c-e150-a590bd337fc9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from segmentation_models import Unet\n",
        "from segmentation_models.backbones import get_preprocessing\n",
        "from segmentation_models.losses import bce_jaccard_loss\n",
        "from segmentation_models.metrics import iou_score\n",
        "\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = get_preprocessing(BACKBONE)\n",
        "\n",
        "x_train = preprocess_input(X_train)\n",
        "x_val = preprocess_input(X_valid)\n",
        "\n",
        "#model = Unet(backbone_name='resnet34', encoder_weights=None, input_shape=(None, None, 1))\n",
        "#compile your model by adding the parameters like optimizer, loss and metrics."
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/classification_models/resnext/__init__.py:4: UserWarning: Current ResNext models are deprecated, use keras.applications ResNeXt models\n",
            "  warnings.warn('Current ResNext models are deprecated, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-578fea740e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpreprocess_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBACKBONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75V-HDlasoo_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6a5705ab-7157-41f8-b604-d4feeadb87ef"
      },
      "source": [
        "#Build your model \n",
        "from keras.layers import Reshape\n",
        "\n",
        "model = Unet(backbone_name = 'resnet34', encoder_weights = None, input_shape = (128, 128, 1)) \n",
        "model.compile(optimizer='Adam', loss=loss, metrics=[dice_coefficient])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 16:41:45.695796 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0624 16:41:45.769834 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0624 16:41:45.771116 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0624 16:41:45.773465 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0624 16:41:45.775383 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0624 16:41:46.038290 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0624 16:41:46.233623 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0624 16:41:49.662674 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0624 16:41:50.777916 139972486903680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0624 16:41:50.801987 139972486903680 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eL1lRlXDpIHl",
        "outputId": "2677e87e-eafe-4bb7-8a06-287fa1f640e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7384
        }
      },
      "source": [
        "#Get the summary of your model\n",
        "model.summary()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, 128, 128, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bn_data (BatchNormalization)    (None, 128, 128, 1)  3           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 1)  0           bn_data[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv0 (Conv2D)                  (None, 64, 64, 64)   3136        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn0 (BatchNormalization)        (None, 64, 64, 64)   256         conv0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "relu0 (Activation)              (None, 64, 64, 64)   0           bn0[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pooling0 (MaxPooling2D)         (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         pooling0[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit1_sc (Conv2D)        (None, 32, 32, 64)   4096        stage1_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           stage1_unit1_conv2[0][0]         \n",
            "                                                                 stage1_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit2_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           stage1_unit2_conv2[0][0]         \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu1 (Activation) (None, 32, 32, 64)   0           stage1_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv1 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_bn2 (BatchNormaliz (None, 32, 32, 64)   256         stage1_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_relu2 (Activation) (None, 32, 32, 64)   0           stage1_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 64)   0           stage1_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage1_unit3_conv2 (Conv2D)     (None, 32, 32, 64)   36864       zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 64)   0           stage1_unit3_conv2[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn1 (BatchNormaliz (None, 32, 32, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu1 (Activation) (None, 32, 32, 64)   0           stage2_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 64)   0           stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv1 (Conv2D)     (None, 16, 16, 128)  73728       zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit1_sc (Conv2D)        (None, 16, 16, 128)  8192        stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 128)  0           stage2_unit1_conv2[0][0]         \n",
            "                                                                 stage2_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit2_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 128)  0           stage2_unit2_conv2[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit3_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 128)  0           stage2_unit3_conv2[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu1 (Activation) (None, 16, 16, 128)  0           stage2_unit4_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit4_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv1 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_bn2 (BatchNormaliz (None, 16, 16, 128)  512         stage2_unit4_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_relu2 (Activation) (None, 16, 16, 128)  0           stage2_unit4_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, 18, 18, 128)  0           stage2_unit4_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage2_unit4_conv2 (Conv2D)     (None, 16, 16, 128)  147456      zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 128)  0           stage2_unit4_conv2[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn1 (BatchNormaliz (None, 16, 16, 128)  512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu1 (Activation) (None, 16, 16, 128)  0           stage3_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, 18, 18, 128)  0           stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv1 (Conv2D)     (None, 8, 8, 256)    294912      zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit1_sc (Conv2D)        (None, 8, 8, 256)    32768       stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 256)    0           stage3_unit1_conv2[0][0]         \n",
            "                                                                 stage3_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_19 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_20 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit2_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_20[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 256)    0           stage3_unit2_conv2[0][0]         \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_21 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_22 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit3_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_22[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 256)    0           stage3_unit3_conv2[0][0]         \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit4_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_23 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit4_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_23[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit4_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit4_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_24 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit4_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit4_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_24[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 256)    0           stage3_unit4_conv2[0][0]         \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit5_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_25 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit5_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_25[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit5_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit5_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_26 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit5_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit5_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_26[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 256)    0           stage3_unit5_conv2[0][0]         \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_relu1 (Activation) (None, 8, 8, 256)    0           stage3_unit6_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_27 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit6_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_conv1 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_27[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_bn2 (BatchNormaliz (None, 8, 8, 256)    1024        stage3_unit6_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_relu2 (Activation) (None, 8, 8, 256)    0           stage3_unit6_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_28 (ZeroPadding2 (None, 10, 10, 256)  0           stage3_unit6_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage3_unit6_conv2 (Conv2D)     (None, 8, 8, 256)    589824      zero_padding2d_28[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 256)    0           stage3_unit6_conv2[0][0]         \n",
            "                                                                 add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn1 (BatchNormaliz (None, 8, 8, 256)    1024        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu1 (Activation) (None, 8, 8, 256)    0           stage4_unit1_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_29 (ZeroPadding2 (None, 10, 10, 256)  0           stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv1 (Conv2D)     (None, 4, 4, 512)    1179648     zero_padding2d_29[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit1_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit1_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_30 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit1_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_30[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit1_sc (Conv2D)        (None, 4, 4, 512)    131072      stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 4, 4, 512)    0           stage4_unit1_conv2[0][0]         \n",
            "                                                                 stage4_unit1_sc[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_31 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_31[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit2_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_32 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit2_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_32[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 4, 4, 512)    0           stage4_unit2_conv2[0][0]         \n",
            "                                                                 add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit3_bn1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_33 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit3_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_33[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit3_conv1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit3_bn2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_34 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit3_relu2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "stage4_unit3_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_34[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 4, 4, 512)    0           stage4_unit3_conv2[0][0]         \n",
            "                                                                 add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 4, 4, 512)    2048        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 4, 4, 512)    0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_upsample (UpSamp (None, 8, 8, 512)    0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           decoder_stage0_upsample[0][0]    \n",
            "                                                                 stage4_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_conv1 (Conv2D)   (None, 8, 8, 256)    1769472     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_bn1 (BatchNormal (None, 8, 8, 256)    1024        decoder_stage0_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_relu1 (Activatio (None, 8, 8, 256)    0           decoder_stage0_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_conv2 (Conv2D)   (None, 8, 8, 256)    589824      decoder_stage0_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_bn2 (BatchNormal (None, 8, 8, 256)    1024        decoder_stage0_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage0_relu2 (Activatio (None, 8, 8, 256)    0           decoder_stage0_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_upsample (UpSamp (None, 16, 16, 256)  0           decoder_stage0_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 384)  0           decoder_stage1_upsample[0][0]    \n",
            "                                                                 stage3_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_conv1 (Conv2D)   (None, 16, 16, 128)  442368      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_bn1 (BatchNormal (None, 16, 16, 128)  512         decoder_stage1_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_relu1 (Activatio (None, 16, 16, 128)  0           decoder_stage1_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_conv2 (Conv2D)   (None, 16, 16, 128)  147456      decoder_stage1_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_bn2 (BatchNormal (None, 16, 16, 128)  512         decoder_stage1_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage1_relu2 (Activatio (None, 16, 16, 128)  0           decoder_stage1_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_upsample (UpSamp (None, 32, 32, 128)  0           decoder_stage1_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 192)  0           decoder_stage2_upsample[0][0]    \n",
            "                                                                 stage2_unit1_relu1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_conv1 (Conv2D)   (None, 32, 32, 64)   110592      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_bn1 (BatchNormal (None, 32, 32, 64)   256         decoder_stage2_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_relu1 (Activatio (None, 32, 32, 64)   0           decoder_stage2_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_conv2 (Conv2D)   (None, 32, 32, 64)   36864       decoder_stage2_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_bn2 (BatchNormal (None, 32, 32, 64)   256         decoder_stage2_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage2_relu2 (Activatio (None, 32, 32, 64)   0           decoder_stage2_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_upsample (UpSamp (None, 64, 64, 64)   0           decoder_stage2_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 64, 64, 128)  0           decoder_stage3_upsample[0][0]    \n",
            "                                                                 relu0[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_conv1 (Conv2D)   (None, 64, 64, 32)   36864       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_bn1 (BatchNormal (None, 64, 64, 32)   128         decoder_stage3_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_relu1 (Activatio (None, 64, 64, 32)   0           decoder_stage3_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_conv2 (Conv2D)   (None, 64, 64, 32)   9216        decoder_stage3_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_bn2 (BatchNormal (None, 64, 64, 32)   128         decoder_stage3_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage3_relu2 (Activatio (None, 64, 64, 32)   0           decoder_stage3_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_upsample (UpSamp (None, 128, 128, 32) 0           decoder_stage3_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_conv1 (Conv2D)   (None, 128, 128, 16) 4608        decoder_stage4_upsample[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_bn1 (BatchNormal (None, 128, 128, 16) 64          decoder_stage4_conv1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_relu1 (Activatio (None, 128, 128, 16) 0           decoder_stage4_bn1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_conv2 (Conv2D)   (None, 128, 128, 16) 2304        decoder_stage4_relu1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_bn2 (BatchNormal (None, 128, 128, 16) 64          decoder_stage4_conv2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "decoder_stage4_relu2 (Activatio (None, 128, 128, 16) 0           decoder_stage4_bn2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "final_conv (Conv2D)             (None, 128, 128, 1)  145         decoder_stage4_relu2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sigmoid (Activation)            (None, 128, 128, 1)  0           final_conv[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 24,449,876\n",
            "Trainable params: 24,432,530\n",
            "Non-trainable params: 17,346\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6UYvb8OdpLV5"
      },
      "source": [
        "### 10. Fit your model using model.fit function.\n",
        "Hint - As it might take long time to run. Run it for only 1 or 2 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bFw1Yq06pQbp",
        "outputId": "26070cd5-dd56-4a43-d07b-7aab317eebc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    batch_size=50,    \n",
        "    epochs=2,\n",
        "    validation_data=(x_val, y_valid)\n",
        ")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-5746c56b709a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iH34vMq9pSnh"
      },
      "source": [
        "### 11.Predict on val set using model.predict funtion and store in preds_val variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FymN5QpopXW-",
        "outputId": "afec54f3-8577-4f8a-d803-cf7be9a8f74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "model.evaluate(x_val, y_valid, verbose=1)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-7092cb9ab863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPcEdYYN3XpX",
        "colab_type": "code",
        "outputId": "dab52e7f-0edc-463b-af6f-7d1a9072b0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "preds_train = model.predict(x_train, verbose=1)\n",
        "preds_val = model.predict(x_val, verbose=1)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-d6d875fd2c6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreds_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uKkpE3vEpXi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "92b7e462-0b05-4061-ae78-82f259e7e01b"
      },
      "source": [
        "#Get the threshold predictions to look at refined results.\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-4101a0dc1a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds_val_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds_val\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'preds_val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pyn3RyCRpaRH",
        "colab": {}
      },
      "source": [
        "#Plot a sample\n",
        "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
        "    if ix is None:\n",
        "        ix = random.randint(0, len(X))\n",
        "\n",
        "    has_mask = y[ix].max() > 0\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
        "    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n",
        "    if has_mask:\n",
        "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[0].set_title('Seismic')\n",
        "\n",
        "    ax[1].imshow(y[ix].squeeze())\n",
        "    ax[1].set_title('Salt')\n",
        "\n",
        "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[2].set_title('Salt Predicted')\n",
        "    \n",
        "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[3].set_title('Salt Predicted binary');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_h5fcgYpbyR",
        "outputId": "f4c228d1-47f9-4d3d-d984-4a7310b177a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# Check if valid data looks all right\n",
        "plot_sample(x_val, y_valid, preds_val, preds_val_t)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-53b552caccf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_val_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_val' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oasnhlaDpeU0"
      },
      "source": [
        "If you are getting good results- Congratulations.\n",
        "If you are not, try to explore what might be the reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yllJR0PQpm4M"
      },
      "source": [
        "# Text generation using a RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2W6g03QsptwG"
      },
      "source": [
        "Given a sequence of words from this data, train a model to predict the next word in the sequence. Longer sequences of text can be generated by calling the model repeatedly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hbd3E0IuHwjz"
      },
      "source": [
        "**Mount your Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8_uTQu4nIGzm",
        "colab": {}
      },
      "source": [
        "#Done"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fnIX_mLXHdxS"
      },
      "source": [
        "### Import Keras and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0TmrQuvpHdxU",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKBXQflGlPjG"
      },
      "source": [
        "## Download data\n",
        "Reference: Data is collected from http://www.gutenberg.org\n",
        "\n",
        "For the lab purpose, you can load the dataset provided by Great Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s321mV4DHdxZ"
      },
      "source": [
        "### Load the Oscar Wilde dataset\n",
        "\n",
        "Store all the \".txt\" file names in a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VUanlzNJHdxa",
        "outputId": "cf6b3514-395b-4748-d3b1-79094c30177f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.chdir('../')\n",
        "os.getcwd()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7y-kfaS75b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_list = glob.glob(\"./data/*.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "glr4hv6uZkL-"
      },
      "source": [
        "### Read the data\n",
        "\n",
        "Read contents of every file from the list and append the text in a new list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLrMMjrkRt9x",
        "colab": {}
      },
      "source": [
        "codetext = []\n",
        "bookranges = []\n",
        "for content in content_list:\n",
        "    content_text = open(content, \"r\")\n",
        "    start = len(codetext)\n",
        "    codetext.append(content_text.read())\n",
        "    end = len(codetext)\n",
        "    bookranges.append({\"start\": start, \"end\": end, \"name\": content.rsplit(\"/\", 1)[-1]})\n",
        "    content_text.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jMX-Fu-GHdxj"
      },
      "source": [
        "## Process the text\n",
        "Initialize and fit the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zQf1AV8wHdxl",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(lower=True, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(codetext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vpZ0A2-xHdxp"
      },
      "source": [
        "### Vectorize the text\n",
        "\n",
        "Before training, we need to map strings to a numerical representation. Create two lookup tables: one mapping words to numbers, and another for numbers to words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Nsq-rSPHdxq",
        "colab": {}
      },
      "source": [
        "word_idx = tokenizer.word_index\n",
        "idx_word = tokenizer.index_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YMYdjx4aHdxu"
      },
      "source": [
        "Get the word count for every word and also get the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ioEZ2c21Hdxw",
        "colab": {}
      },
      "source": [
        "word_counts = tokenizer.word_counts\n",
        "num_words = len(word_idx) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dWUBr9rHHdx0"
      },
      "source": [
        "Convert text to sequence of numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dwLl0BWKHdx2",
        "colab": {}
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(codetext)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GkpK8McUHdx6"
      },
      "source": [
        "### Generate Features and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zxhQamjwHdx7",
        "colab": {}
      },
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "training_length = 50\n",
        "\n",
        "for seq in sequences:\n",
        "\n",
        "    for i in range(training_length, training_length+300):\n",
        "\n",
        "        extract = seq[i - training_length: i - training_length + 20]\n",
        "\n",
        "        features.append(extract[:-1])\n",
        "        labels.append(extract[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bbmsf23Bymwe"
      },
      "source": [
        "### The prediction task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wssHQ1oGymwe"
      },
      "source": [
        "Given a word, or a sequence of words, what is the most probable next word? This is the task we're training the model to perform. The input to the model will be a sequence of words, and we train the model to predict the output—the following word at each time step.\n",
        "\n",
        "Since RNNs maintain an internal state that depends on the previously seen elements, given all the words computed until this moment, what is the next word?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T2bsVOl7HdyA"
      },
      "source": [
        "### Generate training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j7-IsvynHdyB",
        "colab": {}
      },
      "source": [
        "features, labels = shuffle(features, labels, random_state=1)\n",
        "\n",
        "train_end = int(0.7 * len(labels))\n",
        "\n",
        "train_features = np.array(features[:train_end])\n",
        "valid_features = np.array(features[train_end:])\n",
        "\n",
        "train_labels = labels[:train_end]\n",
        "valid_labels = labels[train_end:]\n",
        "\n",
        "X_train, X_valid = np.array(train_features), np.array(valid_features)\n",
        "\n",
        "y_train = np.zeros((len(train_labels), num_words), dtype=np.int8)\n",
        "y_valid = np.zeros((len(valid_labels), num_words), dtype=np.int8)\n",
        "\n",
        "for example_index, word_index in enumerate(train_labels):\n",
        "    y_train[example_index, word_index] = 1\n",
        "\n",
        "for example_index, word_index in enumerate(valid_labels):\n",
        "    y_valid[example_index, word_index] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "juT1mZrUHdyE"
      },
      "source": [
        "This is just to check the features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkdmNbgjHdyF",
        "colab": {}
      },
      "source": [
        "for i, sequence in enumerate(X_train[:2]):\n",
        "    text = []\n",
        "    for idx in sequence:\n",
        "        text.append(idx_word[idx])\n",
        "        \n",
        "    print('Features: ' + ' '.join(text)+'\\n')\n",
        "    print('Label: ' + idx_word[np.argmax(y_train[i])] + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "Use `keras.Sequential` to define the model. For this simple example three layers are used to define our model:\n",
        "\n",
        "* `keras.layers.Embedding`: The input layer. A trainable lookup table that will map the numbers of each character to a vector with `embedding_dim` dimensions;\n",
        "* `keras.layers.LSTM`: A type of RNN with size `units=rnn_units` (You can also use a GRU layer here.)\n",
        "* `keras.layers.Dense`: The output layer, with `num_words` outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GKpCQFZLHdyN",
        "outputId": "2cadfbed-75bc-42bc-bb6d-88f49a392614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(\n",
        "        input_dim=len(word_idx) + 1,\n",
        "        output_dim=100,\n",
        "        weights=None,\n",
        "        trainable=True))\n",
        "\n",
        "model.add(\n",
        "    LSTM(\n",
        "        64, return_sequences=False, dropout=0.1,\n",
        "        recurrent_dropout=0.1))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_words, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0624 16:44:07.303847 139972486903680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         100       \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 46,565\n",
            "Trainable params: 46,565\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vL3tUp1UHdyS"
      },
      "source": [
        "For each word the model looks up the embedding, runs the LSTM one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-liklihood of the next word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6o84puBcHdyV",
        "outputId": "4ea869f9-96d9-4535-ab4b-e3dad1e45857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        }
      },
      "source": [
        "h = model.fit(X_train, y_train, epochs = 20, batch_size = 96, \n",
        "          verbose = 1)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-7940e3a8d264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m h = model.fit(X_train, y_train, epochs = 20, batch_size = 96, \n\u001b[0;32m----> 2\u001b[0;31m           verbose = 1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;31m# using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 check_loss_and_target_compatibility(\n\u001b[0;32m--> 809\u001b[0;31m                     y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 raise ValueError(\n\u001b[1;32m    272\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (0, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "82716QWAJrXG"
      },
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_8MFkQgYJm-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "89f9af18-ecdd-4a91-e7f0-85213d340d93"
      },
      "source": [
        "#model.save('./data/model_40epochs.h5')\n",
        "model.save('../content/gdrive/My Drive/Colab Notebooks/NLP/train/data/model_40epochs.h5')"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-0f6dfed39dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../content/gdrive/My Drive/Colab Notebooks/NLP/train/data/model_40epochs.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '../content/gdrive/My Drive/Colab Notebooks/NLP/train/data/model_40epochs.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4AYVKydVJv5C"
      },
      "source": [
        "## If you have already trained the model and saved it, you can load a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IqsQUz04J0GP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "fab56110-a0a8-4abe-c0ff-1a341d240a76"
      },
      "source": [
        "model = load_model('./data/model_40epochs.h5')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-283c3f5d8b09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/model_40epochs.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = './data/model_40epochs.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZFe2Y0SJJ3Hb"
      },
      "source": [
        "### Note: After loading the model run  model.fit()  to continue training form there, if required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e9yLm_xnJ5JV",
        "outputId": "ca774f8b-ccaf-4a8e-898e-27c7cc6daee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "model.fit(X_train, y_train, batch_size = 64, epochs = 20)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-302c0f8a5cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;31m# using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 check_loss_and_target_compatibility(\n\u001b[0;32m--> 809\u001b[0;31m                     y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 raise ValueError(\n\u001b[1;32m    272\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (0, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EmkaxXdjHdyd"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7RraFX9YHdye",
        "outputId": "7e92ffae-c01b-43c3-9ebf-39bdea62e15e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "print(model.evaluate(X_train, y_train, batch_size = 20))\n",
        "print('\\nModel Performance: Log Loss and Accuracy on validation data')\n",
        "print(model.evaluate(X_valid, y_valid, batch_size = 20))"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-774ea03ae042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nModel Performance: Log Loss and Accuracy on validation data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;31m# using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                 check_loss_and_target_compatibility(\n\u001b[0;32m--> 809\u001b[0;31m                     y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 raise ValueError(\n\u001b[1;32m    272\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (0, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u5CKxykLHdyj"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4JSW5EwKHdyk",
        "outputId": "e0a8285c-0e43-4357-ca53-ef74d3ffc788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "seed_length=50\n",
        "new_words=50\n",
        "diversity=1\n",
        "n_gen=1\n",
        "\n",
        "import random\n",
        "\n",
        "# Choose a random sequence\n",
        "seq = random.choice(sequences)\n",
        "\n",
        "# print seq\n",
        "\n",
        "# Choose a random starting point\n",
        "seed_idx = random.randint(0, len(seq) - seed_length - 10)\n",
        "# Ending index for seed\n",
        "end_idx = seed_idx + seed_length\n",
        "\n",
        "gen_list = []\n",
        "\n",
        "for n in range(n_gen):\n",
        "    # Extract the seed sequence\n",
        "    seed = seq[seed_idx:end_idx]\n",
        "    original_sequence = [idx_word[i] for i in seed]\n",
        "    generated = seed[:] + ['#']\n",
        "\n",
        "    # Find the actual entire sequence\n",
        "    actual = generated[:] + seq[end_idx:end_idx + new_words]\n",
        "        \n",
        "    # Keep adding new words\n",
        "    for i in range(new_words):\n",
        "\n",
        "        # Make a prediction from the seed\n",
        "        preds = model.predict(np.array(seed).reshape(1, -1))[0].astype(np.float64)\n",
        "\n",
        "        # Diversify\n",
        "        preds = np.log(preds) / diversity\n",
        "        exp_preds = np.exp(preds)\n",
        "\n",
        "        # Softmax\n",
        "        preds = exp_preds / sum(exp_preds)\n",
        "\n",
        "        # Choose the next word\n",
        "        probas = np.random.multinomial(1, preds, 1)[0]\n",
        "\n",
        "        next_idx = np.argmax(probas)\n",
        "\n",
        "        # New seed adds on old word\n",
        "        #             seed = seed[1:] + [next_idx]\n",
        "        seed += [next_idx]\n",
        "        generated.append(next_idx)\n",
        "    # Showing generated and actual abstract\n",
        "    n = []\n",
        "\n",
        "    for i in generated:\n",
        "        n.append(idx_word.get(i, '< --- >'))\n",
        "\n",
        "    gen_list.append(n)\n",
        "\n",
        "a = []\n",
        "\n",
        "for i in actual:\n",
        "    a.append(idx_word.get(i, '< --- >'))\n",
        "\n",
        "a = a[seed_length:]\n",
        "\n",
        "gen_list = [gen[seed_length:seed_length + len(a)] for gen in gen_list]\n",
        "\n",
        "print('Original Sequence: \\n'+' '.join(original_sequence))\n",
        "print(\"\\n\")\n",
        "print('Generated Sequence: \\n'+' '.join(gen_list[0][1:]))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-bc50522376ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Choose a random sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# print seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHYo2Fb5YPul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}